{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 60000 images with shape (28, 28) (rows, columns)\n",
      "Loaded 60000 labels\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import struct \n",
    "\n",
    "def load_mnist_images(filename):\n",
    "    # Open the file in read-binary mode\n",
    "    with open(filename, 'rb') as f:\n",
    "        # Read the magic number (first 4 bytes)\n",
    "        magic_number = struct.unpack('>I', f.read(4))[0]\n",
    "\n",
    "        # Check that the file is a 3-dimensional array (magic number should be 2051)\n",
    "        if magic_number != 2051:\n",
    "            raise ValueError(f\"Invalid magic number {magic_number} in file: {filename}\")\n",
    "\n",
    "        # Read the number of images, number of rows, and number of columns\n",
    "        num_images = struct.unpack('>I', f.read(4))[0]\n",
    "        num_rows = struct.unpack('>I', f.read(4))[0]\n",
    "        num_columns = struct.unpack('>I', f.read(4))[0]\n",
    "\n",
    "        # Read the rest of the file as a numpy array of unsigned bytes (uint8)\n",
    "        images = np.frombuffer(f.read(), dtype=np.uint8)\n",
    "\n",
    "        # Reshape the flat array into a 3D array (num_images, height, width)\n",
    "        images = images.reshape(num_images, num_rows, num_columns)\n",
    "\n",
    "        return images\n",
    "    \n",
    "def load_mnist_labels(filename):\n",
    "    # Open the file in read-binary mode\n",
    "    with open(filename, 'rb') as f:\n",
    "        # Read the magic number (first 4 bytes)\n",
    "        magic_number = struct.unpack('>I', f.read(4))[0]\n",
    "\n",
    "        # Check that the file is a 1-dimensional array (magic number should be 2049)\n",
    "        if magic_number != 2049:\n",
    "            raise ValueError(f\"Invalid magic number {magic_number} in file: {filename}\")\n",
    "\n",
    "        # Read the number of labels (next 4 bytes)\n",
    "        num_labels = struct.unpack('>I', f.read(4))[0]\n",
    "\n",
    "        # Read the rest of the file as a numpy array of unsigned bytes (uint8)\n",
    "        labels = np.frombuffer(f.read(), dtype=np.uint8)\n",
    "\n",
    "        return labels\n",
    "\n",
    "# Example usage:\n",
    "filename1 = './archive/train-images.idx3-ubyte'\n",
    "filename2 = './archive/train-labels.idx1-ubyte'\n",
    "images = load_mnist_images(filename1)\n",
    "labels = load_mnist_labels(filename2)\n",
    "\n",
    "print(f\"Loaded {images.shape[0]} images with shape {images.shape[1:]} (rows, columns)\")\n",
    "print(f\"Loaded {labels.shape[0]} labels\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(60000,)\n",
      "(60000, 10)\n"
     ]
    }
   ],
   "source": [
    "def one_hot_encode(labels, num_classes):\n",
    "    # Create a zero matrix of size (number of labels, number of classes)\n",
    "    one_hot_encoded = np.zeros((labels.shape[0], num_classes))\n",
    "    \n",
    "    # Set the corresponding index to 1 for each label\n",
    "    one_hot_encoded[np.arange(labels.shape[0]), labels] = 1\n",
    "    \n",
    "    return one_hot_encoded\n",
    "\n",
    "num_classes = 10  # For MNIST, digits range from 0 to 9, so we have 10 classes\n",
    "one_hot_labels = one_hot_encode(labels, num_classes)\n",
    "#images_light = images[0:4000, :, :]\n",
    "#one_hot_labels_light = one_hot_labels[0:4000, :]\n",
    "\n",
    "print(images.shape)\n",
    "#print(images_light.shape)\n",
    "print(labels.shape)\n",
    "print(one_hot_labels.shape)\n",
    "#print(one_hot_labels_light.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 0.8725562154380216\n",
      "Epoch 10, Loss: 0.6590677979889269\n",
      "Epoch 20, Loss: 0.663944810704661\n",
      "Epoch 30, Loss: 0.7806920558016632\n",
      "Epoch 40, Loss: 0.7918811773148839\n",
      "Epoch 50, Loss: 0.7816344997995878\n",
      "Epoch 60, Loss: 0.7596590268798348\n",
      "Epoch 70, Loss: 0.7361422155296558\n",
      "Epoch 80, Loss: 0.700387801400998\n",
      "Epoch 90, Loss: 0.6428485448306177\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "from ConvNet_functions import TwoDim_Conv_layer, Relu, make_params, forward_prop, softmax,  cross_entropy_loss, backprop\n",
    "from ConvNet_model import create_cnn_model, forward_pass, train_cnn, train_cnn_minibatch\n",
    "\n",
    "input_shape = (6000, 28, 28)  # 1000 images of 28x28 pixels\n",
    "num_classes = 10\n",
    "num_filters = 16\n",
    "kernel_size = 3\n",
    "stride = 1\n",
    "num_epochs = 100\n",
    "learning_rate = 0.001\n",
    "\n",
    "#images_light_labels = one_hot_labels_light.T # y needs to be in shape (num classes, num examples) to be used in train_cnn(), due to cross entropy loss function\n",
    "\n",
    "# Train the model\n",
    "kernels, bias, W, b2 = train_cnn_minibatch(images, one_hot_labels.T , num_epochs, learning_rate, num_filters, kernel_size, stride, batch_size= 32)\n",
    "print('done')\n",
    "# Make predictions\n",
    "#y_pred, _, _, _ = forward_pass(X, kernels, bias, W, b2, stride)\n",
    "#predicted_classes = np.argmax(y_pred, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.9186965847792408\n",
      "Test Accuracy: 93.87%\n"
     ]
    }
   ],
   "source": [
    "# Function to evaluate the model on testing data\n",
    "def evaluate_model(X_test, y_test, kernels, bias, W, b2, stride):\n",
    "    \"\"\"\n",
    "    Evaluates the model on test data.\n",
    "    \n",
    "    Args:\n",
    "    X_test: numpy array of test images (shape: num_examples, height, width)\n",
    "    y_test: numpy array of one-hot encoded test labels (shape: num_classes, num_examples)\n",
    "    kernels, bias, W, b2: trained parameters from the CNN\n",
    "    stride: stride used during the convolution operation\n",
    "    \n",
    "    Returns:\n",
    "    accuracy: The accuracy of the model on the test set\n",
    "    loss: Cross-entropy loss on the test set\n",
    "    \"\"\"\n",
    "    # Perform a forward pass on the test data\n",
    "    y_pred, _, _, _ = forward_pass(X_test, kernels, bias, W, b2, stride)\n",
    "    \n",
    "    # Compute the cross-entropy loss\n",
    "    loss = cross_entropy_loss(y_test, y_pred)\n",
    "    \n",
    "    # Get the predicted class for each test example\n",
    "    predicted_classes = np.argmax(y_pred, axis=0)\n",
    "    \n",
    "    # Get the true class from y_test\n",
    "    true_classes = np.argmax(y_test, axis=0)\n",
    "    \n",
    "    # Compute the accuracy\n",
    "    accuracy = np.mean(predicted_classes == true_classes)\n",
    "    \n",
    "    print(f\"Test Loss: {loss}\")\n",
    "    print(f\"Test Accuracy: {accuracy * 100:.2f}%\")\n",
    "    \n",
    "    return loss, accuracy\n",
    "\n",
    "#Create Testing Data\n",
    "X_test = images[2000:6000, :, :] #using next 1,000 images for testing\n",
    "Y_test = one_hot_labels[2000:6000, :]\n",
    "Y_test_transpose = Y_test.T\n",
    "\n",
    "#Use Other Test Data\n",
    "test_file1 = './archive/t10k-images.idx3-ubyte'\n",
    "test_file2 = './archive/t10k-labels.idx1-ubyte'\n",
    "X_test_legit = load_mnist_images(test_file1)\n",
    "Y_test_legit = one_hot_encode(load_mnist_labels(test_file2), 10)\n",
    "Y_test_legit = Y_test_legit.T\n",
    "\n",
    "#Evaluate on Testing Data\n",
    "test_loss, test_accuracy = evaluate_model(X_test_legit, Y_test_legit, kernels, bias, W, b2, stride)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
