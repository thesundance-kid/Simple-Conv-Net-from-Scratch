{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 60000 images with shape (28, 28) (rows, columns)\n",
      "Loaded 60000 labels\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import struct \n",
    "\n",
    "def load_mnist_images(filename):\n",
    "    # Open the file in read-binary mode\n",
    "    with open(filename, 'rb') as f:\n",
    "        # Read the magic number (first 4 bytes)\n",
    "        magic_number = struct.unpack('>I', f.read(4))[0]\n",
    "\n",
    "        # Check that the file is a 3-dimensional array (magic number should be 2051)\n",
    "        if magic_number != 2051:\n",
    "            raise ValueError(f\"Invalid magic number {magic_number} in file: {filename}\")\n",
    "\n",
    "        # Read the number of images, number of rows, and number of columns\n",
    "        num_images = struct.unpack('>I', f.read(4))[0]\n",
    "        num_rows = struct.unpack('>I', f.read(4))[0]\n",
    "        num_columns = struct.unpack('>I', f.read(4))[0]\n",
    "\n",
    "        # Read the rest of the file as a numpy array of unsigned bytes (uint8)\n",
    "        images = np.frombuffer(f.read(), dtype=np.uint8)\n",
    "\n",
    "        # Reshape the flat array into a 3D array (num_images, height, width)\n",
    "        images = images.reshape(num_images, num_rows, num_columns)\n",
    "\n",
    "        return images\n",
    "    \n",
    "def load_mnist_labels(filename):\n",
    "    # Open the file in read-binary mode\n",
    "    with open(filename, 'rb') as f:\n",
    "        # Read the magic number (first 4 bytes)\n",
    "        magic_number = struct.unpack('>I', f.read(4))[0]\n",
    "\n",
    "        # Check that the file is a 1-dimensional array (magic number should be 2049)\n",
    "        if magic_number != 2049:\n",
    "            raise ValueError(f\"Invalid magic number {magic_number} in file: {filename}\")\n",
    "\n",
    "        # Read the number of labels (next 4 bytes)\n",
    "        num_labels = struct.unpack('>I', f.read(4))[0]\n",
    "\n",
    "        # Read the rest of the file as a numpy array of unsigned bytes (uint8)\n",
    "        labels = np.frombuffer(f.read(), dtype=np.uint8)\n",
    "\n",
    "        return labels\n",
    "\n",
    "# Example usage:\n",
    "filename1 = './archive/train-images.idx3-ubyte'\n",
    "filename2 = './archive/train-labels.idx1-ubyte'\n",
    "images = load_mnist_images(filename1)\n",
    "labels = load_mnist_labels(filename2)\n",
    "\n",
    "print(f\"Loaded {images.shape[0]} images with shape {images.shape[1:]} (rows, columns)\")\n",
    "print(f\"Loaded {labels.shape[0]} labels\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(1000, 28, 28)\n",
      "(60000,)\n",
      "(60000, 10)\n",
      "(1000, 10)\n"
     ]
    }
   ],
   "source": [
    "def one_hot_encode(labels, num_classes):\n",
    "    # Create a zero matrix of size (number of labels, number of classes)\n",
    "    one_hot_encoded = np.zeros((labels.shape[0], num_classes))\n",
    "    \n",
    "    # Set the corresponding index to 1 for each label\n",
    "    one_hot_encoded[np.arange(labels.shape[0]), labels] = 1\n",
    "    \n",
    "    return one_hot_encoded\n",
    "\n",
    "num_classes = 10  # For MNIST, digits range from 0 to 9, so we have 10 classes\n",
    "one_hot_labels = one_hot_encode(labels, num_classes)\n",
    "images_light = images[0:1000, :, :]\n",
    "one_hot_labels_light = one_hot_labels[0:1000, :]\n",
    "\n",
    "print(images.shape)\n",
    "print(images_light.shape)\n",
    "print(labels.shape)\n",
    "print(one_hot_labels.shape)\n",
    "print(one_hot_labels_light.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 3.397333083639657\n",
      "Epoch 10, Loss: 1.2941760172933132\n",
      "Epoch 20, Loss: 2.433777141786067\n",
      "Epoch 30, Loss: 0.028138715868735762\n",
      "Epoch 40, Loss: 0.005547471895715564\n",
      "Epoch 50, Loss: 1.8263151552001642e-05\n",
      "Epoch 60, Loss: 1.2443960047211782e-05\n",
      "Epoch 70, Loss: 1.0065125893745111e-05\n",
      "Epoch 80, Loss: 8.568361451180205e-06\n",
      "Epoch 90, Loss: 7.573886453326661e-06\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 18\u001b[0m\n\u001b[1;32m     15\u001b[0m kernels, bias, W, b2 \u001b[38;5;241m=\u001b[39m train_cnn_minibatch(images_light,images_light_labels, num_epochs, learning_rate, num_filters, kernel_size, stride, batch_size\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m32\u001b[39m)\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# Make predictions\u001b[39;00m\n\u001b[0;32m---> 18\u001b[0m y_pred, _, _, _ \u001b[38;5;241m=\u001b[39m forward_pass(X, kernels, bias, W, b2, stride)\n\u001b[1;32m     19\u001b[0m predicted_classes \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margmax(y_pred, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X' is not defined"
     ]
    }
   ],
   "source": [
    "from ConvNet_functions import TwoDim_Conv_layer, Relu, make_params, forward_prop, softmax,  cross_entropy_loss, backprop\n",
    "from ConvNet_model import create_cnn_model, forward_pass, train_cnn, train_cnn_minibatch\n",
    "\n",
    "input_shape = (1000, 28, 28)  # 1000 images of 28x28 pixels\n",
    "num_classes = 10\n",
    "num_filters = 16\n",
    "kernel_size = 3\n",
    "stride = 1\n",
    "num_epochs = 100\n",
    "learning_rate = 0.0001\n",
    "\n",
    "images_light_labels = one_hot_labels_light.T # y needs to be in shape (num classes, num examples) to be used in train_cnn(), due to cross entropy loss function\n",
    "\n",
    "# Train the model\n",
    "kernels, bias, W, b2 = train_cnn_minibatch(images_light,images_light_labels, num_epochs, learning_rate, num_filters, kernel_size, stride, batch_size= 32)\n",
    "\n",
    "# Make predictions\n",
    "y_pred, _, _, _ = forward_pass(X, kernels, bias, W, b2, stride)\n",
    "predicted_classes = np.argmax(y_pred, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 3.5184759315620258\n",
      "Test Accuracy: 83.70%\n"
     ]
    }
   ],
   "source": [
    "# Function to evaluate the model on testing data\n",
    "def evaluate_model(X_test, y_test, kernels, bias, W, b2, stride):\n",
    "    \"\"\"\n",
    "    Evaluates the model on test data.\n",
    "    \n",
    "    Args:\n",
    "    X_test: numpy array of test images (shape: num_examples, height, width)\n",
    "    y_test: numpy array of one-hot encoded test labels (shape: num_classes, num_examples)\n",
    "    kernels, bias, W, b2: trained parameters from the CNN\n",
    "    stride: stride used during the convolution operation\n",
    "    \n",
    "    Returns:\n",
    "    accuracy: The accuracy of the model on the test set\n",
    "    loss: Cross-entropy loss on the test set\n",
    "    \"\"\"\n",
    "    # Perform a forward pass on the test data\n",
    "    y_pred, _, _, _ = forward_pass(X_test, kernels, bias, W, b2, stride)\n",
    "    \n",
    "    # Compute the cross-entropy loss\n",
    "    loss = cross_entropy_loss(y_test, y_pred)\n",
    "    \n",
    "    # Get the predicted class for each test example\n",
    "    predicted_classes = np.argmax(y_pred, axis=0)\n",
    "    \n",
    "    # Get the true class from y_test\n",
    "    true_classes = np.argmax(y_test, axis=0)\n",
    "    \n",
    "    # Compute the accuracy\n",
    "    accuracy = np.mean(predicted_classes == true_classes)\n",
    "    \n",
    "    print(f\"Test Loss: {loss}\")\n",
    "    print(f\"Test Accuracy: {accuracy * 100:.2f}%\")\n",
    "    \n",
    "    return loss, accuracy\n",
    "\n",
    "#Create Testing Data\n",
    "X_test = images[1000:6000, :, :] #using next 1,000 images for testing\n",
    "Y_test = one_hot_labels[1000:6000, :]\n",
    "Y_test_transpose = Y_test.T\n",
    "\n",
    "#Evaluate on Testing Data\n",
    "test_loss, test_accuracy = evaluate_model(X_test, Y_test_transpose, kernels, bias, W, b2, stride)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
